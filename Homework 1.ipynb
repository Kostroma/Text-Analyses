{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    .widget-label { min-width: 20ex !important; }\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from IPython.display import display, HTML, SVG, Image, display_html\n",
    "pd.set_option('display.max_colwidth', 500)\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "display(HTML('''<style>\n",
    "    .widget-label { min-width: 20ex !important; }\n",
    "</style>'''))\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spam items:  747 , ham items:  4827\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    4827\n",
       "1     747\n",
       "Name: is_spam, dtype: int64"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "file = open('SMSSpamCollection', 'r')\n",
    "data = []\n",
    "answers = []\n",
    "for line in file:\n",
    "    line = line[:-2]\n",
    "    words = line.split('\\t')\n",
    "    data.append(words[1])\n",
    "    answers.append(int(words[0] == 'spam'))\n",
    "data = np.asarray(data)\n",
    "answers = np.asarray(answers)\n",
    "print('spam items: ', sum(answers), ', ham items: ', len(answers) - sum(answers))\n",
    "ds = pd.DataFrame({'text' : data, 'is_spam' : answers})\n",
    "ds.is_spam.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def fill_features(data, pattern = None, range_lens = (1, 1), ignore_words = None):\n",
    "    if pattern is None:\n",
    "        vectorizer = CountVectorizer(ngram_range=range_lens, stop_words=ignore_words)\n",
    "    else:\n",
    "        vectorizer = CountVectorizer(token_pattern=pattern, ngram_range=range_lens, stop_words=ignore_words)\n",
    "    features = vectorizer.fit_transform(data)\n",
    "    return vectorizer, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_regression(features, answers, reg_const = 1.0):\n",
    "    cls = LogisticRegression(C=reg_const)\n",
    "    res = cross_val_score(cls, features, answers, scoring='f1', cv=10)\n",
    "    print('score: ', np.mean(res), '\\t std: ', np.std(res))\n",
    "    return cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score:  0.929816060649 \t std:  0.0171694800418\n"
     ]
    }
   ],
   "source": [
    "#запускаем регрессию с параметром регуляризации по умолчанию (он равен 1.0)\n",
    "#получаем качество ~0.93\n",
    "vectorizer, features = fill_features(data)\n",
    "cls = run_regression(features, ds.is_spam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def run_sample(vectorizer, cls, test_data):\n",
    "    sample = vectorizer.transform(test_data)\n",
    "    print(cls.predict(sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#обучаем классификатор на всей выборке\n",
    "cls.fit(features, ds.is_spam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.18396131592 \t txt\n",
      "1.80586088208 \t text\n",
      "1.77272515013 \t ringtone\n",
      "1.66531251618 \t reply\n",
      "1.60895276342 \t call\n",
      "1.57832188296 \t uk\n",
      "1.5513536655 \t won\n",
      "1.53148565618 \t chat\n",
      "1.45878134274 \t new\n",
      "1.4377818665 \t mobile\n",
      "1.40714640151 \t stop\n",
      "1.37208829243 \t service\n",
      "1.34836003579 \t claim\n",
      "1.21130484069 \t www\n",
      "1.20733832264 \t 88066\n",
      "1.20520090428 \t 150p\n",
      "1.17039655555 \t free\n",
      "1.1438442765 \t cost\n",
      "1.12776279557 \t message\n",
      "1.11562223611 \t com\n"
     ]
    }
   ],
   "source": [
    "def print_important_coefficients(vectorizer, cls, num=20):\n",
    "    coef = cls.coef_[0]\n",
    "    order = np.argsort(abs(coef))[::-1]\n",
    "    params = vectorizer.get_feature_names()\n",
    "    for o in order[:num]:\n",
    "        print(coef[o], '\\t', params[o])\n",
    "#выведем слова с наибольшим абсолютным весом в нашем классификаторе\n",
    "print_important_coefficients(vectorizer, cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "test_data = [\"FreeMsg: Txt: CALL to No: 86888 & claim your reward of 3 hours talk time to use from your phone now! Subscribe6GB\", \\\n",
    "\"FreeMsg: Txt: claim your reward of 3 hours talk time\", \\\n",
    "\"Have you visited the last lecture on physics?\", \\\n",
    "\"Have you visited the last lecture on physics? Just buy this book and you will have all materials! Only 99$\", \\\n",
    "\"Only 99$\"]\n",
    "#предсказываем ответ для тестовых сообщений\n",
    "run_sample(vectorizer, cls, test_data)\n",
    "#последние 2 примера, скорее всего, спрогнозированы неверно"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ngram  (2, 2) :\n",
      "score:  0.814184514368 \t std:  0.0224355190018\n",
      "ngram  (3, 3) :\n",
      "score:  0.723910938924 \t std:  0.0180503756616\n",
      "ngram  (1, 3) :\n",
      "score:  0.919724379882 \t std:  0.0173382780611\n"
     ]
    }
   ],
   "source": [
    "ngrams_to_try = [(2, 2), (3, 3), (1, 3)]\n",
    "for range_ngram in ngrams_to_try:\n",
    "    current_vectorizer, current_features = fill_features(data, range_lens=range_ngram)\n",
    "    print('ngram ', range_ngram, ':')\n",
    "    run_regression(current_features, ds.is_spam)\n",
    "#получаем значения 0.81, 0.72, 0.92"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "naive bayes results:\n",
      "ngram  (1, 1) :\n",
      "score:  0.919974840901 \t std:  0.0135227839017\n",
      "ngram  (2, 2) :\n",
      "score:  0.640145169909 \t std:  0.0207635617755\n",
      "ngram  (3, 3) :\n",
      "score:  0.375578625938 \t std:  0.00939418934033\n",
      "ngram  (1, 3) :\n",
      "score:  0.88395028567 \t std:  0.017013090273\n"
     ]
    }
   ],
   "source": [
    "def run_naive_bayes(features, answers):\n",
    "    cls = MultinomialNB()\n",
    "    res = cross_val_score(cls, features, answers, scoring='f1', cv=10)\n",
    "    print('score: ', np.mean(res), '\\t std: ', np.std(res))\n",
    "    return cls\n",
    "ngrams_to_try = [(1, 1), (2, 2), (3, 3), (1, 3)]\n",
    "print('naive bayes results:')\n",
    "for range_ngram in ngrams_to_try:\n",
    "    current_vectorizer, current_features = fill_features(data, range_lens=range_ngram)\n",
    "    print('ngram ', range_ngram, ':')\n",
    "    run_naive_bayes(current_features, ds.is_spam)\n",
    "#получаем значения 0.92, 0.64, 0.38, 0.88"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf*idf results:\n",
      "score:  0.846901921735 \t std:  0.0261167193081\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "features_tfidf = tfidf.fit_transform(data)\n",
    "print('tf*idf results:')\n",
    "run_regression(features_tfidf, ds.is_spam)\n",
    "#результат с использованием tf*idf хуже, чем с CountVectorizer(): 0.85 вместо 0.93"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def find_feature_by_name(vectorizer, cls, name):\n",
    "    coef = cls.coef_[0]\n",
    "    order = np.argsort(abs(coef))[::-1]\n",
    "    params = vectorizer.get_feature_names()\n",
    "    for o in order:\n",
    "        if params[o] == name:\n",
    "            print(name, ': ', coef[o])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score:  0.934663926912 \t std:  0.0195210726626\n",
      "£ :  2.77278793086\n",
      "2.77278793086 \t £\n",
      "1.99772912681 \t txt\n",
      "1.77586882366 \t text\n",
      "1.77507074611 \t ringtone\n",
      "1.71392034042 \t reply\n",
      "1.58753953635 \t call\n",
      "1.57100383023 \t uk\n",
      "1.46275751673 \t chat\n",
      "1.43983490274 \t service\n",
      "1.4278723663 \t stop\n",
      "1.41664295377 \t new\n",
      "1.37823943574 \t won\n",
      "1.34313047646 \t mobile\n",
      "1.28430908426 \t 150p\n",
      "1.21016338365 \t free\n",
      "1.18114529896 \t message\n",
      "1.17785096002 \t com\n",
      "1.16853646463 \t www\n",
      "1.14085249967 \t cost\n",
      "1.11316270604 \t 88066\n",
      "18 :  1.03767493192\n",
      "$ :  0.350598914559\n",
      "[1 1 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "#в спаме часто встречаются суммы денег с характерными знаками, будем учитывать их\n",
    "current_vectorizer, current_features = fill_features(data, pattern=r'([A-Za-z0-9][A-Za-z0-9]+|[$]|[€]|[£])')\n",
    "current_cls = run_regression(current_features, ds.is_spam)\n",
    "current_cls.fit(current_features, ds.is_spam)\n",
    "find_feature_by_name(current_vectorizer, current_cls, '£')\n",
    "print_important_coefficients(current_vectorizer, current_cls)\n",
    "find_feature_by_name(current_vectorizer, current_cls, '18')\n",
    "find_feature_by_name(current_vectorizer, current_cls, '$')\n",
    "#качество улучшается на ~0.007\n",
    "#хотелось добавить признаки 16+ и 18+, но с запихиванием паттерна с плюсом в CountVectorizer возникли некоторые проблемы, почему-то он не распознается \n",
    "#Впрочем, оказалось, что классификатор выбрал числа 16 и 18 как признаки спама (видимо он сплиттит по плюсу)\n",
    "run_sample(current_vectorizer, current_cls, test_data)\n",
    "#на тестовых данных все то же самое"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score:  0.929784865079 \t std:  0.0180973223562\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#the - самое частовстречающееся слово в английском, причем кажется, что его отрицательный вес обусловлен только преобладанием отрицательных примеров в выборке\n",
    "#пробуем убрать его из признаков\n",
    "current_vectorizer, current_features = fill_features(data, ignore_words=['the'])\n",
    "run_regression(current_features, ds.is_spam)\n",
    "#качество незначительно ухудшается"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score:  0.929816060649 \t std:  0.0171694800418\n",
      "foroldonly :  0.402337418062\n"
     ]
    }
   ],
   "source": [
    "#попробуем теперь обработать отдельно 16+ и 18+ - заменим в данных их на слово foroldonly\n",
    "def insert_forold_in_data(data):\n",
    "    res_data = []\n",
    "    for line in data:\n",
    "        line = re.sub('16\\+', r' foroldonly ', line)\n",
    "        line = re.sub('18\\+', r' foroldonly ', line)\n",
    "        res_data.append(line)\n",
    "    return np.asarray(res_data)\n",
    "processed_data = insert_forold_in_data(data)\n",
    "current_vectorizer, current_features = fill_features(processed_data)\n",
    "current_cls = run_regression(current_features, ds.is_spam)\n",
    "current_cls.fit(current_features, ds.is_spam)\n",
    "find_feature_by_name(current_vectorizer, current_cls, 'foroldonly')\n",
    "#качество не меняется по сравнению с вариантом по умолчанию, по-видимому все вхождения чисел 16 и 18 в датасет связаны именно с возрастными ограничениями"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score:  0.952850166505 \t std:  0.019746294382\n",
      "telephonenumber :  4.37185582468\n",
      "[-4.69779586]\n",
      "4.37185582468 \t telephonenumber\n",
      "2.04645900537 \t £\n",
      "1.61702223298 \t txt\n",
      "1.59573596412 \t reply\n",
      "1.49163169899 \t mobile\n",
      "1.44365799387 \t uk\n",
      "1.4385530076 \t ringtone\n",
      "1.40573326052 \t text\n",
      "1.29617980629 \t www\n",
      "1.27921112096 \t tones\n",
      "1.13919473872 \t content\n",
      "1.13483485173 \t new\n",
      "1.10508485464 \t free\n",
      "1.09828217139 \t won\n",
      "-1.04165039106 \t my\n",
      "1.02562289005 \t chat\n",
      "0.980160965074 \t order\n",
      "0.975591969536 \t 146tf150\n",
      "0.975057743241 \t stop\n",
      "-0.965375858511 \t gt\n",
      "[1 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "#в спам часто входят какие-то длинные строчки из цифр - по-видимому, номера телефонов, иногда они разделены пробелами на несколько групп цифр. \n",
    "#Заменим все такие подозрительные позиции в данных на слово telephonenumber\n",
    "def insert_telephone_numbers_in_data(data):\n",
    "    res_data = []\n",
    "    for line in data:\n",
    "        line = re.sub('([0-9][ ]*[0-9][ ]*[0-9][ ]*[0-9][ ]*([0-9][ ]*)+)', r' telephonenumber ', line)\n",
    "        res_data.append(line)\n",
    "    return np.asarray(res_data)\n",
    "processed_data = insert_telephone_numbers_in_data(data)\n",
    "current_vectorizer, current_features = fill_features(processed_data, pattern=r'([A-Za-z0-9][A-Za-z0-9]+|[$]|[€]|[£])')\n",
    "current_cls = run_regression(current_features, ds.is_spam)\n",
    "current_cls.fit(current_features, ds.is_spam)\n",
    "find_feature_by_name(current_vectorizer, current_cls, 'telephonenumber')\n",
    "print(current_cls.intercept_)\n",
    "print_important_coefficients(current_vectorizer, current_cls)\n",
    "#качество на кросс-валидации улучшается на 0.02\n",
    "#однако, новый признак имеет слишком большое влияние по сравнению с остальными, и у остальных признаков веса уменьшились по сравнению с исходным вариантом\n",
    "run_sample(current_vectorizer, current_cls, test_data)\n",
    "#на небольшой тестовой выборке второй пример теперь прогнозируется неправильно, видимо не хватает суммы положительных признаков из-за уменьшения их коэффициентов, \n",
    "#а самый жирным признак telephonenumber сюда не подошел"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_number_of_errors(features, cls):\n",
    "    ds['prediction'] = cls.predict(features)\n",
    "    ds['prediction_proba'] = cls.predict_proba(features)[:,1]\n",
    "    ds['confidence'] = np.abs(ds.prediction_proba - 0.5)*2\n",
    "    errors = ds.loc[ds.is_spam != ds.prediction]\n",
    "    return len(errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reg_const:  0.1\n",
      "score:  0.898796417611 \t std:  0.0193635646676\n",
      "82\n",
      "1.30499646563 \t txt\n",
      "1.28555866483 \t call\n",
      "1.03412274497 \t text\n",
      "0.902327190097 \t reply\n",
      "0.833659680354 \t free\n",
      "[1 0 0 0 0]\n",
      "reg_const:  0.5\n",
      "score:  0.924664015195 \t std:  0.0163204089542\n",
      "33\n",
      "1.91740903899 \t txt\n",
      "1.57745156337 \t text\n",
      "1.51871131232 \t call\n",
      "1.43011710889 \t reply\n",
      "1.35501688129 \t ringtone\n",
      "[1 1 0 0 0]\n",
      "reg_const:  1\n",
      "score:  0.929816060649 \t std:  0.0171694800418\n",
      "12\n",
      "2.18396131592 \t txt\n",
      "1.80586088208 \t text\n",
      "1.77272515013 \t ringtone\n",
      "1.66531251618 \t reply\n",
      "1.60895276342 \t call\n",
      "[1 1 0 0 0]\n",
      "reg_const:  2\n",
      "score:  0.932691178624 \t std:  0.0189261733054\n",
      "4\n",
      "2.45580921947 \t txt\n",
      "2.20126666191 \t ringtone\n",
      "2.02744972204 \t text\n",
      "1.90383768069 \t 146tf150\n",
      "1.89963515513 \t reply\n",
      "[1 1 0 0 0]\n",
      "reg_const:  5\n",
      "score:  0.93699774907 \t std:  0.0181106684031\n",
      "2\n",
      "4.06541723626 \t 146tf150\n",
      "2.82442955557 \t txt\n",
      "2.78474895019 \t ringtone\n",
      "2.69139618149 \t ringtoneking\n",
      "2.6913581922 \t 8448\n",
      "[1 1 0 0 0]\n",
      "reg_const:  10\n",
      "score:  0.939728510798 \t std:  0.0194246998957\n",
      "1\n",
      "5.75529203246 \t 146tf150\n",
      "3.36892322993 \t ringtoneking\n",
      "3.3686052042 \t 8448\n",
      "3.2479561715 \t ringtone\n",
      "3.11424090265 \t txt\n",
      "[1 1 0 0 0]\n",
      "reg_const:  100\n",
      "score:  0.942576439102 \t std:  0.0171853078261\n",
      "0\n",
      "10.2069170589 \t 146tf150\n",
      "5.46801477976 \t ringtoneking\n",
      "5.46495325092 \t 8448\n",
      "4.8954413047 \t ringtone\n",
      "4.12713827963 \t txt\n",
      "[1 1 0 0 0]\n",
      "reg_const:  1000\n",
      "score:  0.941835505544 \t std:  0.0169660385004\n",
      "0\n",
      "14.5539846164 \t 146tf150\n",
      "7.61236262526 \t ringtoneking\n",
      "7.6013361353 \t 8448\n",
      "6.67143887851 \t ringtone\n",
      "5.28607242548 \t txt\n",
      "[1 1 0 0 0]\n",
      "reg_const:  10000\n",
      "score:  0.943356064173 \t std:  0.0163186327861\n",
      "0\n",
      "18.4544840597 \t 146tf150\n",
      "9.57069883437 \t ringtoneking\n",
      "9.5573045032 \t 8448\n",
      "8.31003134616 \t ringtone\n",
      "6.79861503146 \t 0709020152\n",
      "[1 1 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "#пробуем разные параметры регуляризации\n",
    "reg_consts = [0.1, 0.5, 1, 2, 5, 10, 100, 1000, 10000]\n",
    "for c in reg_consts:\n",
    "    print('reg_const: ', c)\n",
    "    current_cls = run_regression(features, ds.is_spam, reg_const=c)\n",
    "    current_cls.fit(features, ds.is_spam)\n",
    "    print(get_number_of_errors(features, current_cls))\n",
    "    print_important_coefficients(vectorizer, current_cls, 5)\n",
    "    run_sample(vectorizer, current_cls, test_data)\n",
    "#при больших c увеличивается score на кросс-валидации, но коэффициенты увеличиваются, т.к. регуляризация по сути отключается. \n",
    "#при больших c модель, обученная по всей выборке, не ошибается ни на одном элементе выборки\n",
    "#Скорее всего, модель с большим c сильно переобучена - например, в ней появляются с большими коэффициентами слова, встретившиеся только в одном сообщении - для работы на новых данных эти признаки, по сути, бесполезны"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Выводы: неплохое качество классификации можно получить связкой CountVectorizer + LogisticRegression. Качество можно несколько улучшить, если учитывать некоторые специфичные детали спама -\n",
    "#например, суммы в валюте или длинные номера. Однако в процессе важно не переобучиться, поэтому лучше обучаться сразу на нескольких коллекциях, т.к. велик риск подстроить классификатор\n",
    "#под конкретную коллекцию. Для того, чтобы использовать биграммы и получить с них улучшение качества, нужны коллекции размером сильно больше, чем 5000 в нашей выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
